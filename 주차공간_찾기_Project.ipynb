{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "주차공간 찾기 Project",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1qu9IDKNS1YawY_h9kbGWcE2xCKKS9dFn",
      "authorship_tag": "ABX9TyNwuINFvi4fGl+J+Mt0kgEn"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fjfj7ZtuUZD"
      },
      "source": [
        "# 알집 푸는 코드\r\n",
        "!unzip CNRPark-Patches-150x150-20210107T023432Z-001.zip -d CNRPark-Patches-150x150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap5h1I99xuaT"
      },
      "source": [
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import glob\r\n",
        "import os\r\n",
        "from tqdm import tqdm\r\n",
        "from pathlib import Path\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torchvision import transforms, datasets\r\n",
        "from torch.utils.data import Dataset\r\n",
        "\r\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xZ7WeBIyFR7",
        "outputId": "d2e711ef-f426-48aa-9c0d-35ea264e1a9c"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwEWLIbI-uW7"
      },
      "source": [
        "### 학습을 위한 모델 설계"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvfNloiIGFm9"
      },
      "source": [
        "class UltraSimpleParkingSpaceClassificationNet(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(UltraSimpleParkingSpaceClassificationNet, self).__init__()\r\n",
        "    self.layers = nn.Sequential(      # convolution model\r\n",
        "        nn.Conv2d(3, 32, 3 ,padding=1),   # input_channel:3, output_channel:32, kernel의 크기: 3\r\n",
        "        nn.ReLU()\r\n",
        "    )   \r\n",
        "\r\n",
        "    self.fc_layers = nn.Sequential(\r\n",
        "        nn.Linear(150 * 150 * 32, 100),\r\n",
        "        nn.ReLU(),\r\n",
        "        nn.Linear(100, 2)\r\n",
        "    )\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    out = self.layers(x)\r\n",
        "    out = out.view(BATCH_SIZE, -1)\r\n",
        "    out = self.fc_layers(out)\r\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUYf8m2FVXbr"
      },
      "source": [
        "class ImageMultiFolder(Dataset):\r\n",
        "  def __init__(self, data_root):\r\n",
        "    self.imgNames = []\r\n",
        "\r\n",
        "    for parkingLot in os.listdir(data_root):\r\n",
        "      parkingLotPath = os.path.join(data_root, parkingLot)\r\n",
        "      for statePath in os.listdir(parkingLotPath):\r\n",
        "        img_filepath = os.path.join(parkingLotPath, statePath)\r\n",
        "        for img in os.listdir(img_filepath):\r\n",
        "          migPath = os.path.koin(img_filepath, img)\r\n",
        "          self.imgNames.append(imgPath)\r\n",
        "  \r\n",
        "  def __len__(self):\r\n",
        "    return len(self.imgNames)\r\n",
        "\r\n",
        "  def __getitem__(self, idx):\r\n",
        "    img = cv2.imread(self.imgNames[idx])\r\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(no.float32) / 255.0\r\n",
        "    if 'busy' in self.imgNames[idx]:\r\n",
        "      state = 0\r\n",
        "    else:\r\n",
        "      state = 1\r\n",
        "    \r\n",
        "    img_tensor = torch.from_numpy(img.transpose(2,0,1))\r\n",
        "    return img_tensor, state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVJkhhoKyPP6"
      },
      "source": [
        "# DIR_path = Path('./CNRPark-Patches-150x150/CNRPark-Patches-150x150/A/free')\r\n",
        "# DIR_path = Path('./CNRPark-Patches-150x150/CNRPark-Patches-150x150/A/busy')\r\n",
        "# DIR_path = Path('./CNRPark-Patches-150x150/CNRPark-Patches-150x150/B/free')\r\n",
        "DIR_path = Path('./CNRPark-Patches-150x150/CNRPark-Patches-150x150/B/busy')\r\n",
        "files_list = DIR_path.iterdir()\r\n",
        "\r\n",
        "for f in files_list:\r\n",
        "  img = cv2.imread(str(f))    # 문자로 읽어온다.\r\n",
        "\r\n",
        "  if img is None:     # 사진이 없다면\r\n",
        "    print('unable to open', f)\r\n",
        "  else:               # 사진이 존재한다면\r\n",
        "    h, w, c = img.shape     # 사진의 height, width, channel을 불러온다.\r\n",
        "    if h != 150 or w != 150 or c != 3:    # 세개 조건중 하나라도 맞지 않는다면\r\n",
        "      print('image', f, 'has wrong dimension : ', img.shape)\r\n",
        "      resized = cv2.resize(img, dsize=(150, 150), interpolation=cv2.INTER_AREA)     # 사진 크기를 150 x 150으로 조정\r\n",
        "      cv2.imwrite(str(f), resized)  # 다시 덮어 쓴다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "JxPPhVWz8Q1g",
        "outputId": "e97ea1b0-1b2f-4dec-a201-89a42f760456"
      },
      "source": [
        "# image_datasets = datasets.ImageFolder('./CNRPark-Patches-150x150/CNRPark-Patches-150x150/A',\r\n",
        "#                                       transform = transforms.ToTensor())     # 이미지를 텐서로 변환\r\n",
        "# image_datasets = datasets.ImageFolder('./CNRPark-Patches-150x150/CNRPark-Patches-150x150/B',\r\n",
        "#                                       transform = transforms.ToTensor()\r\n",
        "image_datasets = ImageMultiFolder('./CNRPark-Patches-150x150')\r\n",
        "\r\n",
        "# 이미지를 보기 위한 코드\r\n",
        "# dataloader = torch.utils.data.DataLoader(image_datasets, batch_size=1, shuffle=True, num_workers=8)\r\n",
        "\r\n",
        "# for img, label in dataloader:   # 이미지를 dataloader로 가져오게 되면 이미지와 label을 같이 가지고 있음\r\n",
        "#   imgToShow = img.numpy()   # tensor로 되어있으니까 numpy로 바꿔주는 작업\r\n",
        "#   print(imgToShow.shape)\r\n",
        "#   print(label)\r\n",
        "#   imgToShow = np.transpose(imgToShow[0], (1,2,0))\r\n",
        "#   # numpy에서 사용하는 이미지 배열과 tensor가 사용하는 순서(height, width, channels)가 다르기 때문에 transpose를 해주는 것\r\n",
        "#   plt.imshow(imgToShow)\r\n",
        "#   plt.show()\r\n",
        "\r\n",
        "\r\n",
        "# train과 test 대이터 나누기\r\n",
        "\r\n",
        "train_size = int(len(image_datasets)*0.8)\r\n",
        "test_size = len(image_datasets) - train_size\r\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(image_datasets, [train_size, test_size])\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, \r\n",
        "                                           batch_size = BATCH_SIZE, \r\n",
        "                                           shuffle=True, \r\n",
        "                                           num_workers=8, \r\n",
        "                                           drop_last=True)\r\n",
        "\r\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, \r\n",
        "                                          batch_size = BATCH_SIZE, \r\n",
        "                                          shuffle=True, \r\n",
        "                                          num_workers=8, \r\n",
        "                                          drop_last=True)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1a8486e74617>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# image_datasets = datasets.ImageFolder('./CNRPark-Patches-150x150/CNRPark-Patches-150x150/B',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#                                       transform = transforms.ToTensor()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimage_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageMultiFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./CNRPark-Patches-150x150'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 이미지를 보기 위한 코드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-bf544bced5a0>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_root)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mimg_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparkingLotPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m           \u001b[0mmigPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgNames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'posixpath' has no attribute 'koin'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVGoHUbUI8vq"
      },
      "source": [
        "### 학습 환경 설정\r\n",
        "#### Loss: CrossEntropy\r\n",
        "#### Optimizer : Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw9dLnxKATfw"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda. is_available() else 'cpu')    # 불러올 수 없는 환경이라면 cpu로\r\n",
        "model = UltraSimpleParkingSpaceClassificationNet().to(device)\r\n",
        "model = model.train()     # 학습모드\r\n",
        "loss_func = nn.CrossEntropyLoss()\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0002)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCG8J-x_KsBV"
      },
      "source": [
        "### 학습 시작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kxn8uccFhVj",
        "outputId": "d928a4cd-a429-42b7-b17a-4ac9f89df86b"
      },
      "source": [
        "num_epoch = 10\r\n",
        "\r\n",
        "for i in range(num_epoch):\r\n",
        "  for j, [image, label] in enumerate(train_loader):\r\n",
        "    x = image.to(device)\r\n",
        "    y_ = label.to(device)\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "    output = model.forward(x)\r\n",
        "    loss = loss_func(output, y_)\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    if j % 100 == 0:\r\n",
        "      print('epoch:', i, ', batch:', j, ', loss is:', loss.data.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0 , batch: 0 , loss is: 0.6875128746032715\n",
            "epoch: 1 , batch: 0 , loss is: 0.6365188360214233\n",
            "epoch: 2 , batch: 0 , loss is: 0.009958493523299694\n",
            "epoch: 3 , batch: 0 , loss is: 0.014750929549336433\n",
            "epoch: 4 , batch: 0 , loss is: 0.006372322794049978\n",
            "epoch: 5 , batch: 0 , loss is: 0.0021463935263454914\n",
            "epoch: 6 , batch: 0 , loss is: 0.000578028557356447\n",
            "epoch: 7 , batch: 0 , loss is: 0.0003426806360948831\n",
            "epoch: 8 , batch: 0 , loss is: 0.0011546829482540488\n",
            "epoch: 9 , batch: 0 , loss is: 0.0004250503552611917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD-yDq4DKtfK"
      },
      "source": [
        "### 테스트 시작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZonKy3JKZla",
        "outputId": "44d5e865-6a1d-4b9b-c52b-f66d873c122a"
      },
      "source": [
        "correct = 0\r\n",
        "total = 0\r\n",
        "model = model.eval()\r\n",
        "\r\n",
        "with torch. no_grad():\r\n",
        "   for image, label in test_loader:\r\n",
        "     x = image.to(device)\r\n",
        "     y_ = label.to(device)\r\n",
        "\r\n",
        "     output = model.forward(x)\r\n",
        "     _, output_index = torch.max(output, 1)   # index만 가지고 비교\r\n",
        "\r\n",
        "     total += label.size(0)\r\n",
        "     correct += (output_index == y_).sum().float()\r\n",
        "\r\n",
        "print('Total: {}, Correct: {}'.format(total, correct))\r\n",
        "print('Accuracy of Test Data: {}'.format(100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total: 1216, Correct: 1216.0\n",
            "Accuracy of Test Data: 100.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}