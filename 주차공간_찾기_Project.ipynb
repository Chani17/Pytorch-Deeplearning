{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "주차공간 찾기 Project",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1qu9IDKNS1YawY_h9kbGWcE2xCKKS9dFn",
      "authorship_tag": "ABX9TyOnFbfoSfzNJJ4UKj6tczQs"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fjfj7ZtuUZD"
      },
      "source": [
        "# 알집 푸는 코드\r\n",
        "!unzip CNRPark-Patches-150x150-20210107T023432Z-001.zip -d CNRPark-Patches-150x150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap5h1I99xuaT"
      },
      "source": [
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import glob\r\n",
        "import os\r\n",
        "from tqdm import tqdm\r\n",
        "from pathlib import Path\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torchvision import transforms, datasets\r\n",
        "from torch.utils.data import Dataset\r\n",
        "\r\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xZ7WeBIyFR7",
        "outputId": "a2e2ee96-8bff-4284-eca3-d8dd129b9cfe"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwEWLIbI-uW7"
      },
      "source": [
        "### 학습을 위한 모델 설계"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvfNloiIGFm9"
      },
      "source": [
        "class UltraSimpleParkingSpaceClassificationNet(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(UltraSimpleParkingSpaceClassificationNet, self).__init__()\r\n",
        "    self.layers = nn.Sequential(      # convolution model\r\n",
        "        nn.Conv2d(3, 32, 3 ,padding=1),   # input_channel:3, output_channel:32, kernel의 크기: 3\r\n",
        "        nn.ReLU()\r\n",
        "    )   \r\n",
        "\r\n",
        "    self.fc_layers = nn.Sequential(\r\n",
        "        nn.Linear(150 * 150 * 32, 100),\r\n",
        "        nn.ReLU(),\r\n",
        "        nn.Linear(100, 2)\r\n",
        "    )\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    out = self.layers(x)\r\n",
        "    out = out.view(BATCH_SIZE, -1)\r\n",
        "    out = self.fc_layers(out)\r\n",
        "    return out"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUYf8m2FVXbr"
      },
      "source": [
        "class ImageMultiFolder(Dataset):\r\n",
        "  def __init__(self, data_root):\r\n",
        "    self.imgNames = []\r\n",
        "\r\n",
        "    for parkingLot in os.listdir(data_root):\r\n",
        "      parkingLotPath = os.path.join(data_root, parkingLot)    # os.path.join: data_root과 parkingLot 두 개의 경로를 합쳐주는 역할\r\n",
        "      for statePath in os.listdir(parkingLotPath):\r\n",
        "        img_filepath = os.path.join(parkingLotPath, statePath)\r\n",
        "        for img in os.listdir(img_filepath):\r\n",
        "          imgPath = os.path.join(img_filepath, img)\r\n",
        "          self.imgNames.append(imgPath)\r\n",
        "  \r\n",
        "  def __len__(self):\r\n",
        "    return len(self.imgNames)\r\n",
        "\r\n",
        "  def __getitem__(self, idx):   # 메소드가 데이터로부터 값을 가져올 때 실행되는 메소드\r\n",
        "    img = cv2.imread(self.imgNames[idx])\r\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\r\n",
        "    if 'busy' in self.imgNames[idx]:\r\n",
        "      state = 0\r\n",
        "    else:\r\n",
        "      state = 1\r\n",
        "    \r\n",
        "    img_tensor = torch.from_numpy(img.transpose(2,0,1))\r\n",
        "    return img_tensor, state"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVJkhhoKyPP6"
      },
      "source": [
        "# DIR_path = Path('./CNRPark-Patches-150x150/CNRPark-Patches-150x150/A/free')\r\n",
        "# DIR_path = Path('./CNRPark-Patches-150x150/CNRPark-Patches-150x150/A/busy')\r\n",
        "# DIR_path = Path('./CNRPark-Patches-150x150/CNRPark-Patches-150x150/B/free')\r\n",
        "DIR_path = Path('./CNRPark-Patches-150x150/CNRPark-Patches-150x150/B/busy')\r\n",
        "files_list = DIR_path.iterdir()\r\n",
        "\r\n",
        "for f in files_list:\r\n",
        "  img = cv2.imread(str(f))    # 문자로 읽어온다.\r\n",
        "\r\n",
        "  if img is None:     # 사진이 없다면\r\n",
        "    print('unable to open', f)\r\n",
        "  else:               # 사진이 존재한다면\r\n",
        "    h, w, c = img.shape     # 사진의 height, width, channel을 불러온다.\r\n",
        "    if h != 150 or w != 150 or c != 3:    # 세개 조건중 하나라도 맞지 않는다면\r\n",
        "      print('image', f, 'has wrong dimension : ', img.shape)\r\n",
        "      resized = cv2.resize(img, dsize=(150, 150), interpolation=cv2.INTER_AREA)     # 사진 크기를 150 x 150으로 조정\r\n",
        "      cv2.imwrite(str(f), resized)  # 다시 덮어 쓴다."
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxPPhVWz8Q1g"
      },
      "source": [
        "# image_datasets = datasets.ImageFolder('./CNRPark-Patches-150x150/CNRPark-Patches-150x150/A',\r\n",
        "#                                       transform = transforms.ToTensor())     # 이미지를 텐서로 변환\r\n",
        "# image_datasets = datasets.ImageFolder('./CNRPark-Patches-150x150/CNRPark-Patches-150x150/B',\r\n",
        "#                                       transform = transforms.ToTensor()\r\n",
        "image_datasets = ImageMultiFolder('./CNRPark-Patches-150x150/CNRPark-Patches-150x150')\r\n",
        "\r\n",
        "# 이미지를 보기 위한 코드\r\n",
        "# dataloader = torch.utils.data.DataLoader(image_datasets, batch_size=1, shuffle=True, num_workers=8)\r\n",
        "\r\n",
        "# for img, label in dataloader:   # 이미지를 dataloader로 가져오게 되면 이미지와 label을 같이 가지고 있음\r\n",
        "#   imgToShow = img.numpy()   # tensor로 되어있으니까 numpy로 바꿔주는 작업\r\n",
        "#   print(imgToShow.shape)\r\n",
        "#   print(label)\r\n",
        "#   imgToShow = np.transpose(imgToShow[0], (1,2,0))\r\n",
        "#   # numpy에서 사용하는 이미지 배열과 tensor가 사용하는 순서(height, width, channels)가 다르기 때문에 transpose를 해주는 것\r\n",
        "#   plt.imshow(imgToShow)\r\n",
        "#   plt.show()\r\n",
        "\r\n",
        "\r\n",
        "# train과 test 대이터 나누기\r\n",
        "\r\n",
        "train_size = int(len(image_datasets)*0.8)\r\n",
        "test_size = len(image_datasets) - train_size\r\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(image_datasets, [train_size, test_size])\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, \r\n",
        "                                           batch_size = BATCH_SIZE, \r\n",
        "                                           shuffle=True, \r\n",
        "                                           num_workers=8, \r\n",
        "                                           drop_last=True)\r\n",
        "\r\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, \r\n",
        "                                          batch_size = BATCH_SIZE, \r\n",
        "                                          shuffle=True, \r\n",
        "                                          num_workers=8, \r\n",
        "                                          drop_last=True)\r\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVGoHUbUI8vq"
      },
      "source": [
        "### 학습 환경 설정\r\n",
        "#### Loss: CrossEntropy\r\n",
        "#### Optimizer : Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw9dLnxKATfw"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')    # 불러올 수 없는 환경이라면 cpu로\r\n",
        "model = UltraSimpleParkingSpaceClassificationNet().to(device)\r\n",
        "model = model.train()     # 학습모드\r\n",
        "loss_func = nn.CrossEntropyLoss()\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0002)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCG8J-x_KsBV"
      },
      "source": [
        "### 학습 시작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZOnsXgcUkcP",
        "outputId": "af6d9013-615d-4c6a-9f77-2a45873edefc"
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvPdcMzsUppH"
      },
      "source": [
        "#### **pytorch version 1.7에는 다음과 같은 에러가 남. 이를 1.5로 돌릴경우 잘 돌아간다고 한다.**\r\n",
        "###### RuntimeError: stack expects each tensor to be equal size, but got [3, 150, 150] at entry 0 and [3, 150, 127] at entry 31"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "7Kxn8uccFhVj",
        "outputId": "1a9c5570-3859-41b5-8c89-c04e391178f6"
      },
      "source": [
        "# pytorch 버전이 1.7에는 \r\n",
        "num_epoch = 5\r\n",
        "\r\n",
        "for i in range(num_epoch):\r\n",
        "  for j, [image, label] in enumerate(train_loader):\r\n",
        "    x = image.to(device)\r\n",
        "    y_ = label.to(device)\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "    output = model.forward(x)\r\n",
        "    loss = loss_func(output, y_)\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    if j % 100 == 0:\r\n",
        "      print('epoch:', i, ', batch:', j, ', loss is:', loss.data.item())"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-f5eb878687bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 83, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 83, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 150, 150] at entry 0 and [3, 150, 127] at entry 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD-yDq4DKtfK"
      },
      "source": [
        "### 테스트 시작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "sZonKy3JKZla",
        "outputId": "6ccc30b0-7889-4bde-c0e7-889f20b641eb"
      },
      "source": [
        "correct = 0\r\n",
        "total = 0\r\n",
        "model = model.eval()\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "   for image, label in test_loader:\r\n",
        "     x = image.to(device)\r\n",
        "     y_ = label.to(device)\r\n",
        "\r\n",
        "     output = model.forward(x)\r\n",
        "     _, output_index = torch.max(output, 1)   # index만 가지고 비교\r\n",
        "\r\n",
        "     total += label.size(0)\r\n",
        "     correct += (output_index == y_).sum().float()\r\n",
        "\r\n",
        "print('Total: {}, Correct: {}'.format(total, correct))\r\n",
        "print('Accuracy of Test Data: {}'.format(100 * correct / total))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-2c42199bc298>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m      \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m      \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 83, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 83, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 150, 150] at entry 0 and [3, 150, 113] at entry 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "RAcm9UZRREwj",
        "outputId": "135d58df-e3ab-49c6-a902-046401341163"
      },
      "source": [
        "from google.colab import files\r\n",
        "torch.save(model.state_dict(), 'ultraSimpleParkingSpaceClassificationModel.pth')\r\n",
        "files.download('ultraSimpleParkingSpaceClassificationModel.pth')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_3cd2fa11-a44b-4456-b5df-2d7221692e64\", \"ultraSimpleParkingSpaceClassificationModel.pth\", 288007169)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k77w9dQbT-Zr",
        "outputId": "8bcb5554-e784-4561-bdb7-c6e53c67dfbe"
      },
      "source": [
        "# 기존에 있는 모델을 불러와 추가로 학습을 시키거나 또는 성능을 평가하거나 할 수 있음\r\n",
        "state_dict = torch.load('ultraSimpleParkingSpaceClassificationModel.pth')\r\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    }
  ]
}