{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic regression을 활용한 손글씨 숫자 구분하기",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNddvxgHJZ5O3HSQUTItHqc"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQlFdStPE55p"
      },
      "source": [
        "## 손글씨 숫자 데이터와 ground truth\r\n",
        "- 손글씨 숫자 이미지는 8x8크기의 gray \r\n",
        "- 이미지 데이터는 64개의 숫자로 저장\r\n",
        "- 숫자 종류는 10가지: 0 ~ 9\r\n",
        "- 이미지는 모두 1,797장\r\n",
        "- 데이터는 numpy의 ndarray로 저장"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yql9yDvEFggE"
      },
      "source": [
        "### 손글씨 숫자데이터 분류"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDRIzGFxEkeb"
      },
      "source": [
        "import torch\r\n",
        "from torch import nn, optim\r\n",
        "from sklearn.datasets import load_digits\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EKzCVUWFqwq",
        "outputId": "90d85f01-1c7a-4660-de84-28ef82a73845"
      },
      "source": [
        "digits = load_digits()\r\n",
        "\r\n",
        "X = digits.data\r\n",
        "print(type(X))\r\n",
        "print(X.shape)\r\n",
        "\r\n",
        "y = digits.target\r\n",
        "print(type(y))\r\n",
        "print(y.shape)\r\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(1797, 64)\n",
            "<class 'numpy.ndarray'>\n",
            "(1797,)\n",
            "[0 1 2 ... 8 9 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1dLKImcGTxt"
      },
      "source": [
        "### 손글씨 숫자 Visualization\r\n",
        "- 손글씨 데이터 64를 8x8로 reshaping\r\n",
        "- color map을 gray로 설정\r\n",
        "- 픽셀 값들은 0 ~ 16: 0은 검정, 16은 white"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "W-DjMpUxF14X",
        "outputId": "c290f172-713a-4811-fbd7-6516a09e0f39"
      },
      "source": [
        "i = 12\r\n",
        "\r\n",
        "num = X[i]\r\n",
        "print(num.shape)\r\n",
        "num = num.reshape((8,8))  # 64행 1열을 8행 8열로 바꾼다.\r\n",
        "print(num.shape)\r\n",
        "print(num)\r\n",
        "plt.imshow(num, cmap='gray')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64,)\n",
            "(8, 8)\n",
            "[[ 0.  0.  5. 12.  1.  0.  0.  0.]\n",
            " [ 0.  0. 15. 14.  7.  0.  0.  0.]\n",
            " [ 0.  0. 13.  1. 12.  0.  0.  0.]\n",
            " [ 0.  2. 10.  0. 14.  0.  0.  0.]\n",
            " [ 0.  0.  2.  0. 16.  1.  0.  0.]\n",
            " [ 0.  0.  0.  6. 15.  0.  0.  0.]\n",
            " [ 0.  0.  9. 16. 15.  9.  8.  2.]\n",
            " [ 0.  0.  3. 11.  8. 13. 12.  4.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PjqE1MTHHG6"
      },
      "source": [
        "### 학습과 테스트를 위한 데이터 준비 \r\n",
        "- 학습용 : 1,617장\r\n",
        "- 테스트용 : 180장"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx2hoLlKHN2E"
      },
      "source": [
        "### 학습과 테스트 데이터 분류"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlS6E9xjGpnp",
        "outputId": "5e0b0b93-efc0-47f6-f513-8bcaeb3bcdca"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True)\r\n",
        "\r\n",
        "print('Type: x_train, y_train, x_test, y_test')\r\n",
        "print(type(x_train), type(y_train), type(x_test), type(y_test))\r\n",
        "\r\n",
        "print('Type: x_train, y_train, x_test, y_test')\r\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type: x_train, y_train, x_test, y_test\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "Type: x_train, y_train, x_test, y_test\n",
            "(1617, 64) (1617,) (180, 64) (180,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vptt9ZOMIWNQ"
      },
      "source": [
        "### 학습 모델과 GPU 활용\r\n",
        "- Linear model: 64 -> 10\r\n",
        "- Loss: Cross Entropy\r\n",
        "- Optimizer: Stochastic Gradient Descent\r\n",
        "- GPU 활용을 위해서 학습과 테스트 데이터는 GPU로 이동"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj4WIfQzIlsU"
      },
      "source": [
        "### 학습을 위한 모델, Loss, Optimizer 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9cAvLHIH2Jh"
      },
      "source": [
        "net = nn.Linear(64,10)\r\n",
        "loss_fn = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpBDnqJQI6vv"
      },
      "source": [
        "### Tensor로 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "er0WlZxuI5_-",
        "outputId": "63fb3002-fde7-465f-a713-9b19b61167f0"
      },
      "source": [
        "x_train = torch.tensor(x_train, dtype=torch.float).to('cuda')\r\n",
        "y_train = torch.tensor(y_train, dtype=torch.long).to('cuda')\r\n",
        "x_test = torch.tensor(x_test, dtype=torch.float).to('cuda')\r\n",
        "y_test = torch.tensor(y_test, dtype=torch.long).to('cuda')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d2Qvv5bJ11C"
      },
      "source": [
        "##학습 진행과 loss값의 변화\r\n",
        "### 학습시작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK9IAIZaJUaH",
        "outputId": "034377b1-1774-4df7-85ee-0329d0b1f4df"
      },
      "source": [
        "losses = []\r\n",
        "net.train()\r\n",
        "net.to('cuda')\r\n",
        "\r\n",
        "for epoc in range(600):\r\n",
        "\r\n",
        "  optimizer.zero_grad()\r\n",
        "\r\n",
        "  y_pred = net(x_train)\r\n",
        "  loss = loss_fn(y_pred, y_train)\r\n",
        "  loss.backward()\r\n",
        "\r\n",
        "  optimizer.step()\r\n",
        "  losses.append(loss.item())\r\n",
        "  print(epoc, 'Loss: ', loss.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Loss:  7.1946940422058105\n",
            "1 Loss:  4.951577186584473\n",
            "2 Loss:  3.335580825805664\n",
            "3 Loss:  2.80987286567688\n",
            "4 Loss:  2.1830105781555176\n",
            "5 Loss:  1.8918546438217163\n",
            "6 Loss:  1.6785495281219482\n",
            "7 Loss:  1.4875942468643188\n",
            "8 Loss:  1.3586448431015015\n",
            "9 Loss:  1.2213499546051025\n",
            "10 Loss:  1.1325994729995728\n",
            "11 Loss:  1.0265984535217285\n",
            "12 Loss:  0.955477774143219\n",
            "13 Loss:  0.8763065338134766\n",
            "14 Loss:  0.8193393349647522\n",
            "15 Loss:  0.7631116509437561\n",
            "16 Loss:  0.7192438840866089\n",
            "17 Loss:  0.6795251965522766\n",
            "18 Loss:  0.6463198065757751\n",
            "19 Loss:  0.616976797580719\n",
            "20 Loss:  0.5912261009216309\n",
            "21 Loss:  0.5681625008583069\n",
            "22 Loss:  0.5473394393920898\n",
            "23 Loss:  0.5283721089363098\n",
            "24 Loss:  0.5109923481941223\n",
            "25 Loss:  0.49499180912971497\n",
            "26 Loss:  0.4802039861679077\n",
            "27 Loss:  0.46649104356765747\n",
            "28 Loss:  0.4537366032600403\n",
            "29 Loss:  0.44184038043022156\n",
            "30 Loss:  0.4307161867618561\n",
            "31 Loss:  0.4202888309955597\n",
            "32 Loss:  0.4104931354522705\n",
            "33 Loss:  0.4012712240219116\n",
            "34 Loss:  0.39257270097732544\n",
            "35 Loss:  0.38435259461402893\n",
            "36 Loss:  0.376571387052536\n",
            "37 Loss:  0.369193434715271\n",
            "38 Loss:  0.3621871769428253\n",
            "39 Loss:  0.35552430152893066\n",
            "40 Loss:  0.34917929768562317\n",
            "41 Loss:  0.34312903881073\n",
            "42 Loss:  0.33735278248786926\n",
            "43 Loss:  0.3318316638469696\n",
            "44 Loss:  0.32654857635498047\n",
            "45 Loss:  0.3214878737926483\n",
            "46 Loss:  0.3166353404521942\n",
            "47 Loss:  0.3119778335094452\n",
            "48 Loss:  0.30750349164009094\n",
            "49 Loss:  0.3032013177871704\n",
            "50 Loss:  0.299061119556427\n",
            "51 Loss:  0.29507380723953247\n",
            "52 Loss:  0.29123052954673767\n",
            "53 Loss:  0.2875235378742218\n",
            "54 Loss:  0.283945232629776\n",
            "55 Loss:  0.2804889976978302\n",
            "56 Loss:  0.2771483361721039\n",
            "57 Loss:  0.2739173471927643\n",
            "58 Loss:  0.27079057693481445\n",
            "59 Loss:  0.2677628695964813\n",
            "60 Loss:  0.2648293673992157\n",
            "61 Loss:  0.2619856595993042\n",
            "62 Loss:  0.259227454662323\n",
            "63 Loss:  0.2565508484840393\n",
            "64 Loss:  0.25395211577415466\n",
            "65 Loss:  0.2514278292655945\n",
            "66 Loss:  0.24897465109825134\n",
            "67 Loss:  0.2465895414352417\n",
            "68 Loss:  0.2442694902420044\n",
            "69 Loss:  0.2420119196176529\n",
            "70 Loss:  0.2398141324520111\n",
            "71 Loss:  0.23767367005348206\n",
            "72 Loss:  0.23558825254440308\n",
            "73 Loss:  0.23355570435523987\n",
            "74 Loss:  0.2315739542245865\n",
            "75 Loss:  0.22964097559452057\n",
            "76 Loss:  0.22775499522686005\n",
            "77 Loss:  0.2259141057729721\n",
            "78 Loss:  0.22411668300628662\n",
            "79 Loss:  0.22236113250255585\n",
            "80 Loss:  0.2206459939479828\n",
            "81 Loss:  0.2189697027206421\n",
            "82 Loss:  0.2173309028148651\n",
            "83 Loss:  0.21572832763195038\n",
            "84 Loss:  0.21416063606739044\n",
            "85 Loss:  0.21262671053409576\n",
            "86 Loss:  0.21112537384033203\n",
            "87 Loss:  0.2096555233001709\n",
            "88 Loss:  0.20821605622768402\n",
            "89 Loss:  0.20680607855319977\n",
            "90 Loss:  0.20542456209659576\n",
            "91 Loss:  0.20407059788703918\n",
            "92 Loss:  0.20274333655834198\n",
            "93 Loss:  0.20144183933734894\n",
            "94 Loss:  0.20016543567180634\n",
            "95 Loss:  0.19891327619552612\n",
            "96 Loss:  0.1976846307516098\n",
            "97 Loss:  0.19647879898548126\n",
            "98 Loss:  0.1952950656414032\n",
            "99 Loss:  0.1941327303647995\n",
            "100 Loss:  0.19299134612083435\n",
            "101 Loss:  0.19187010824680328\n",
            "102 Loss:  0.19076849520206451\n",
            "103 Loss:  0.18968598544597626\n",
            "104 Loss:  0.18862198293209076\n",
            "105 Loss:  0.18757598102092743\n",
            "106 Loss:  0.18654753267765045\n",
            "107 Loss:  0.18553610146045685\n",
            "108 Loss:  0.18454128503799438\n",
            "109 Loss:  0.1835624724626541\n",
            "110 Loss:  0.18259944021701813\n",
            "111 Loss:  0.18165165185928345\n",
            "112 Loss:  0.18071871995925903\n",
            "113 Loss:  0.17980027198791504\n",
            "114 Loss:  0.1788959503173828\n",
            "115 Loss:  0.17800530791282654\n",
            "116 Loss:  0.17712818086147308\n",
            "117 Loss:  0.17626401782035828\n",
            "118 Loss:  0.17541258037090302\n",
            "119 Loss:  0.1745736002922058\n",
            "120 Loss:  0.1737467497587204\n",
            "121 Loss:  0.1729317009449005\n",
            "122 Loss:  0.17212818562984467\n",
            "123 Loss:  0.17133593559265137\n",
            "124 Loss:  0.1705547273159027\n",
            "125 Loss:  0.16978417336940765\n",
            "126 Loss:  0.16902413964271545\n",
            "127 Loss:  0.16827437281608582\n",
            "128 Loss:  0.16753457486629486\n",
            "129 Loss:  0.16680459678173065\n",
            "130 Loss:  0.1660841852426529\n",
            "131 Loss:  0.16537310183048248\n",
            "132 Loss:  0.1646711677312851\n",
            "133 Loss:  0.1639781892299652\n",
            "134 Loss:  0.1632939577102661\n",
            "135 Loss:  0.16261830925941467\n",
            "136 Loss:  0.16195103526115417\n",
            "137 Loss:  0.1612919121980667\n",
            "138 Loss:  0.16064085066318512\n",
            "139 Loss:  0.15999764204025269\n",
            "140 Loss:  0.15936213731765747\n",
            "141 Loss:  0.15873418748378754\n",
            "142 Loss:  0.15811356902122498\n",
            "143 Loss:  0.157500222325325\n",
            "144 Loss:  0.15689396858215332\n",
            "145 Loss:  0.15629467368125916\n",
            "146 Loss:  0.15570218861103058\n",
            "147 Loss:  0.15511636435985565\n",
            "148 Loss:  0.15453709661960602\n",
            "149 Loss:  0.15396423637866974\n",
            "150 Loss:  0.15339770913124084\n",
            "151 Loss:  0.1528373509645462\n",
            "152 Loss:  0.15228304266929626\n",
            "153 Loss:  0.15173469483852386\n",
            "154 Loss:  0.15119218826293945\n",
            "155 Loss:  0.15065538883209229\n",
            "156 Loss:  0.15012423694133759\n",
            "157 Loss:  0.149598628282547\n",
            "158 Loss:  0.14907841384410858\n",
            "159 Loss:  0.14856354892253876\n",
            "160 Loss:  0.14805388450622559\n",
            "161 Loss:  0.14754940569400787\n",
            "162 Loss:  0.1470499485731125\n",
            "163 Loss:  0.14655545353889465\n",
            "164 Loss:  0.1460658460855484\n",
            "165 Loss:  0.14558103680610657\n",
            "166 Loss:  0.1451009064912796\n",
            "167 Loss:  0.1446254402399063\n",
            "168 Loss:  0.14415451884269714\n",
            "169 Loss:  0.14368808269500732\n",
            "170 Loss:  0.1432260274887085\n",
            "171 Loss:  0.14276832342147827\n",
            "172 Loss:  0.1423148810863495\n",
            "173 Loss:  0.14186561107635498\n",
            "174 Loss:  0.14142048358917236\n",
            "175 Loss:  0.14097939431667328\n",
            "176 Loss:  0.14054231345653534\n",
            "177 Loss:  0.14010916650295258\n",
            "178 Loss:  0.1396798938512802\n",
            "179 Loss:  0.13925442099571228\n",
            "180 Loss:  0.1388326734304428\n",
            "181 Loss:  0.1384146511554718\n",
            "182 Loss:  0.1380002498626709\n",
            "183 Loss:  0.13758942484855652\n",
            "184 Loss:  0.1371821165084839\n",
            "185 Loss:  0.1367783099412918\n",
            "186 Loss:  0.13637790083885193\n",
            "187 Loss:  0.13598088920116425\n",
            "188 Loss:  0.1355871856212616\n",
            "189 Loss:  0.1351967602968216\n",
            "190 Loss:  0.13480953872203827\n",
            "191 Loss:  0.13442547619342804\n",
            "192 Loss:  0.1340446174144745\n",
            "193 Loss:  0.1336667537689209\n",
            "194 Loss:  0.13329200446605682\n",
            "195 Loss:  0.1329202502965927\n",
            "196 Loss:  0.1325514316558838\n",
            "197 Loss:  0.13218553364276886\n",
            "198 Loss:  0.13182255625724792\n",
            "199 Loss:  0.13146235048770905\n",
            "200 Loss:  0.131104975938797\n",
            "201 Loss:  0.13075034320354462\n",
            "202 Loss:  0.1303984522819519\n",
            "203 Loss:  0.1300492286682129\n",
            "204 Loss:  0.12970267236232758\n",
            "205 Loss:  0.12935872375965118\n",
            "206 Loss:  0.12901736795902252\n",
            "207 Loss:  0.128678560256958\n",
            "208 Loss:  0.12834224104881287\n",
            "209 Loss:  0.1280084252357483\n",
            "210 Loss:  0.1276770383119583\n",
            "211 Loss:  0.12734809517860413\n",
            "212 Loss:  0.12702150642871857\n",
            "213 Loss:  0.12669730186462402\n",
            "214 Loss:  0.12637540698051453\n",
            "215 Loss:  0.12605582177639008\n",
            "216 Loss:  0.1257384866476059\n",
            "217 Loss:  0.12542341649532318\n",
            "218 Loss:  0.12511053681373596\n",
            "219 Loss:  0.12479984015226364\n",
            "220 Loss:  0.12449130415916443\n",
            "221 Loss:  0.12418488413095474\n",
            "222 Loss:  0.12388060986995697\n",
            "223 Loss:  0.12357840687036514\n",
            "224 Loss:  0.12327826768159866\n",
            "225 Loss:  0.12298011779785156\n",
            "226 Loss:  0.12268399447202682\n",
            "227 Loss:  0.12238986790180206\n",
            "228 Loss:  0.12209770083427429\n",
            "229 Loss:  0.12180744111537933\n",
            "230 Loss:  0.12151909619569778\n",
            "231 Loss:  0.12123266607522964\n",
            "232 Loss:  0.12094809859991074\n",
            "233 Loss:  0.12066539376974106\n",
            "234 Loss:  0.12038449198007584\n",
            "235 Loss:  0.12010540813207626\n",
            "236 Loss:  0.11982811987400055\n",
            "237 Loss:  0.11955258995294571\n",
            "238 Loss:  0.11927881091833115\n",
            "239 Loss:  0.11900673806667328\n",
            "240 Loss:  0.1187363937497139\n",
            "241 Loss:  0.11846774071455002\n",
            "242 Loss:  0.11820074170827866\n",
            "243 Loss:  0.11793540418148041\n",
            "244 Loss:  0.11767170578241348\n",
            "245 Loss:  0.1174096092581749\n",
            "246 Loss:  0.11714911460876465\n",
            "247 Loss:  0.11689021438360214\n",
            "248 Loss:  0.1166328713297844\n",
            "249 Loss:  0.11637706309556961\n",
            "250 Loss:  0.11612281203269958\n",
            "251 Loss:  0.11587008088827133\n",
            "252 Loss:  0.11561883240938187\n",
            "253 Loss:  0.11536907404661179\n",
            "254 Loss:  0.1151207759976387\n",
            "255 Loss:  0.11487393081188202\n",
            "256 Loss:  0.11462850868701935\n",
            "257 Loss:  0.11438453197479248\n",
            "258 Loss:  0.11414198577404022\n",
            "259 Loss:  0.1139008104801178\n",
            "260 Loss:  0.113661028444767\n",
            "261 Loss:  0.11342258751392365\n",
            "262 Loss:  0.11318553239107132\n",
            "263 Loss:  0.11294979602098465\n",
            "264 Loss:  0.11271537840366364\n",
            "265 Loss:  0.11248230189085007\n",
            "266 Loss:  0.11225050687789917\n",
            "267 Loss:  0.11202000081539154\n",
            "268 Loss:  0.111790731549263\n",
            "269 Loss:  0.11156277358531952\n",
            "270 Loss:  0.11133608967065811\n",
            "271 Loss:  0.11111058294773102\n",
            "272 Loss:  0.11088632792234421\n",
            "273 Loss:  0.1106632873415947\n",
            "274 Loss:  0.11044146120548248\n",
            "275 Loss:  0.11022081971168518\n",
            "276 Loss:  0.11000135540962219\n",
            "277 Loss:  0.10978304594755173\n",
            "278 Loss:  0.10956594347953796\n",
            "279 Loss:  0.10934992134571075\n",
            "280 Loss:  0.10913508385419846\n",
            "281 Loss:  0.1089213415980339\n",
            "282 Loss:  0.10870874673128128\n",
            "283 Loss:  0.10849722474813461\n",
            "284 Loss:  0.10828681290149689\n",
            "285 Loss:  0.10807749629020691\n",
            "286 Loss:  0.1078692302107811\n",
            "287 Loss:  0.10766204446554184\n",
            "288 Loss:  0.10745590925216675\n",
            "289 Loss:  0.10725083947181702\n",
            "290 Loss:  0.10704678297042847\n",
            "291 Loss:  0.10684378445148468\n",
            "292 Loss:  0.10664176195859909\n",
            "293 Loss:  0.10644078999757767\n",
            "294 Loss:  0.10624078661203384\n",
            "295 Loss:  0.1060417965054512\n",
            "296 Loss:  0.10584378987550735\n",
            "297 Loss:  0.1056467592716217\n",
            "298 Loss:  0.10545068234205246\n",
            "299 Loss:  0.10525557398796082\n",
            "300 Loss:  0.10506141185760498\n",
            "301 Loss:  0.10486817359924316\n",
            "302 Loss:  0.10467588901519775\n",
            "303 Loss:  0.10448451340198517\n",
            "304 Loss:  0.10429408401250839\n",
            "305 Loss:  0.10410455614328384\n",
            "306 Loss:  0.10391589254140854\n",
            "307 Loss:  0.10372816026210785\n",
            "308 Loss:  0.10354132205247879\n",
            "309 Loss:  0.10335535556077957\n",
            "310 Loss:  0.10317026078701019\n",
            "311 Loss:  0.10298601537942886\n",
            "312 Loss:  0.10280264914035797\n",
            "313 Loss:  0.10262010991573334\n",
            "314 Loss:  0.10243844240903854\n",
            "315 Loss:  0.10225759446620941\n",
            "316 Loss:  0.10207760334014893\n",
            "317 Loss:  0.10189840942621231\n",
            "318 Loss:  0.10172003507614136\n",
            "319 Loss:  0.10154245793819427\n",
            "320 Loss:  0.10136571526527405\n",
            "321 Loss:  0.1011897474527359\n",
            "322 Loss:  0.10101457685232162\n",
            "323 Loss:  0.10084020346403122\n",
            "324 Loss:  0.10066661238670349\n",
            "325 Loss:  0.10049375146627426\n",
            "326 Loss:  0.1003217101097107\n",
            "327 Loss:  0.10015041381120682\n",
            "328 Loss:  0.09997986257076263\n",
            "329 Loss:  0.09981004148721695\n",
            "330 Loss:  0.09964098781347275\n",
            "331 Loss:  0.09947267919778824\n",
            "332 Loss:  0.09930509328842163\n",
            "333 Loss:  0.09913825243711472\n",
            "334 Loss:  0.09897210448980331\n",
            "335 Loss:  0.09880666434764862\n",
            "336 Loss:  0.09864193946123123\n",
            "337 Loss:  0.09847795963287354\n",
            "338 Loss:  0.09831465035676956\n",
            "339 Loss:  0.0981520339846611\n",
            "340 Loss:  0.09799009561538696\n",
            "341 Loss:  0.09782887250185013\n",
            "342 Loss:  0.09766829758882523\n",
            "343 Loss:  0.09750840067863464\n",
            "344 Loss:  0.09734916687011719\n",
            "345 Loss:  0.09719062596559525\n",
            "346 Loss:  0.09703271836042404\n",
            "347 Loss:  0.09687546640634537\n",
            "348 Loss:  0.09671887010335922\n",
            "349 Loss:  0.09656291455030441\n",
            "350 Loss:  0.09640760719776154\n",
            "351 Loss:  0.0962529256939888\n",
            "352 Loss:  0.096098892390728\n",
            "353 Loss:  0.09594546258449554\n",
            "354 Loss:  0.09579265117645264\n",
            "355 Loss:  0.09564049541950226\n",
            "356 Loss:  0.09548889845609665\n",
            "357 Loss:  0.09533794224262238\n",
            "358 Loss:  0.09518761187791824\n",
            "359 Loss:  0.09503783285617828\n",
            "360 Loss:  0.09488867223262787\n",
            "361 Loss:  0.0947401151061058\n",
            "362 Loss:  0.09459210932254791\n",
            "363 Loss:  0.09444475173950195\n",
            "364 Loss:  0.09429790824651718\n",
            "365 Loss:  0.09415168315172195\n",
            "366 Loss:  0.0940059944987297\n",
            "367 Loss:  0.09386089444160461\n",
            "368 Loss:  0.09371637552976608\n",
            "369 Loss:  0.09357239305973053\n",
            "370 Loss:  0.09342896193265915\n",
            "371 Loss:  0.09328608959913254\n",
            "372 Loss:  0.09314378350973129\n",
            "373 Loss:  0.09300200641155243\n",
            "374 Loss:  0.09286076575517654\n",
            "375 Loss:  0.09272004663944244\n",
            "376 Loss:  0.0925799012184143\n",
            "377 Loss:  0.09244029223918915\n",
            "378 Loss:  0.09230116754770279\n",
            "379 Loss:  0.0921625941991806\n",
            "380 Loss:  0.09202452003955841\n",
            "381 Loss:  0.0918869897723198\n",
            "382 Loss:  0.09174995869398117\n",
            "383 Loss:  0.09161341935396194\n",
            "384 Loss:  0.09147743135690689\n",
            "385 Loss:  0.09134190529584885\n",
            "386 Loss:  0.09120691567659378\n",
            "387 Loss:  0.09107241034507751\n",
            "388 Loss:  0.09093838185071945\n",
            "389 Loss:  0.09080487489700317\n",
            "390 Loss:  0.0906718298792839\n",
            "391 Loss:  0.09053927659988403\n",
            "392 Loss:  0.09040719270706177\n",
            "393 Loss:  0.0902756005525589\n",
            "394 Loss:  0.09014447778463364\n",
            "395 Loss:  0.09001385420560837\n",
            "396 Loss:  0.08988365530967712\n",
            "397 Loss:  0.08975395560264587\n",
            "398 Loss:  0.08962470293045044\n",
            "399 Loss:  0.0894959419965744\n",
            "400 Loss:  0.08936760574579239\n",
            "401 Loss:  0.08923973143100739\n",
            "402 Loss:  0.0891123116016388\n",
            "403 Loss:  0.08898533880710602\n",
            "404 Loss:  0.08885880559682846\n",
            "405 Loss:  0.0887327566742897\n",
            "406 Loss:  0.08860711008310318\n",
            "407 Loss:  0.08848190307617188\n",
            "408 Loss:  0.08835713565349579\n",
            "409 Loss:  0.08823282271623611\n",
            "410 Loss:  0.08810892701148987\n",
            "411 Loss:  0.08798546344041824\n",
            "412 Loss:  0.08786241710186005\n",
            "413 Loss:  0.08773980289697647\n",
            "414 Loss:  0.08761759847402573\n",
            "415 Loss:  0.0874958336353302\n",
            "416 Loss:  0.08737447112798691\n",
            "417 Loss:  0.08725351840257645\n",
            "418 Loss:  0.08713296800851822\n",
            "419 Loss:  0.08701284974813461\n",
            "420 Loss:  0.08689311146736145\n",
            "421 Loss:  0.0867738202214241\n",
            "422 Loss:  0.08665487915277481\n",
            "423 Loss:  0.08653637021780014\n",
            "424 Loss:  0.08641824871301651\n",
            "425 Loss:  0.08630052208900452\n",
            "426 Loss:  0.08618317544460297\n",
            "427 Loss:  0.08606625348329544\n",
            "428 Loss:  0.08594967424869537\n",
            "429 Loss:  0.08583351224660873\n",
            "430 Loss:  0.08571772277355194\n",
            "431 Loss:  0.08560231328010559\n",
            "432 Loss:  0.08548730611801147\n",
            "433 Loss:  0.08537263423204422\n",
            "434 Loss:  0.0852583646774292\n",
            "435 Loss:  0.08514447510242462\n",
            "436 Loss:  0.0850309431552887\n",
            "437 Loss:  0.08491778373718262\n",
            "438 Loss:  0.08480498194694519\n",
            "439 Loss:  0.0846925675868988\n",
            "440 Loss:  0.08458048850297928\n",
            "441 Loss:  0.0844687893986702\n",
            "442 Loss:  0.08435744047164917\n",
            "443 Loss:  0.08424645662307739\n",
            "444 Loss:  0.08413580060005188\n",
            "445 Loss:  0.084025539457798\n",
            "446 Loss:  0.0839155986905098\n",
            "447 Loss:  0.08380601555109024\n",
            "448 Loss:  0.08369678258895874\n",
            "449 Loss:  0.0835878998041153\n",
            "450 Loss:  0.08347935229539871\n",
            "451 Loss:  0.08337115496397018\n",
            "452 Loss:  0.08326327055692673\n",
            "453 Loss:  0.08315575867891312\n",
            "454 Loss:  0.08304857462644577\n",
            "455 Loss:  0.08294172585010529\n",
            "456 Loss:  0.08283519744873047\n",
            "457 Loss:  0.08272900432348251\n",
            "458 Loss:  0.08262314647436142\n",
            "459 Loss:  0.08251761645078659\n",
            "460 Loss:  0.08241240680217743\n",
            "461 Loss:  0.08230752497911453\n",
            "462 Loss:  0.08220294862985611\n",
            "463 Loss:  0.08209872245788574\n",
            "464 Loss:  0.08199478685855865\n",
            "465 Loss:  0.08189118653535843\n",
            "466 Loss:  0.08178789913654327\n",
            "467 Loss:  0.08168492466211319\n",
            "468 Loss:  0.08158227056264877\n",
            "469 Loss:  0.08147991448640823\n",
            "470 Loss:  0.08137787878513336\n",
            "471 Loss:  0.08127614110708237\n",
            "472 Loss:  0.08117470890283585\n",
            "473 Loss:  0.08107359707355499\n",
            "474 Loss:  0.08097277581691742\n",
            "475 Loss:  0.08087226003408432\n",
            "476 Loss:  0.0807720497250557\n",
            "477 Loss:  0.08067212998867035\n",
            "478 Loss:  0.08057252317667007\n",
            "479 Loss:  0.08047319948673248\n",
            "480 Loss:  0.08037417382001877\n",
            "481 Loss:  0.08027543127536774\n",
            "482 Loss:  0.08017697930335999\n",
            "483 Loss:  0.08007883280515671\n",
            "484 Loss:  0.07998094707727432\n",
            "485 Loss:  0.0798833817243576\n",
            "486 Loss:  0.07978609204292297\n",
            "487 Loss:  0.07968907803297043\n",
            "488 Loss:  0.07959236204624176\n",
            "489 Loss:  0.07949592173099518\n",
            "490 Loss:  0.07939974218606949\n",
            "491 Loss:  0.07930386811494827\n",
            "492 Loss:  0.07920826226472855\n",
            "493 Loss:  0.0791129395365715\n",
            "494 Loss:  0.07901788502931595\n",
            "495 Loss:  0.07892307639122009\n",
            "496 Loss:  0.07882858067750931\n",
            "497 Loss:  0.07873434573411942\n",
            "498 Loss:  0.07864038646221161\n",
            "499 Loss:  0.0785466805100441\n",
            "500 Loss:  0.07845326513051987\n",
            "501 Loss:  0.07836008071899414\n",
            "502 Loss:  0.0782671794295311\n",
            "503 Loss:  0.07817453891038895\n",
            "504 Loss:  0.07808216661214828\n",
            "505 Loss:  0.07799005508422852\n",
            "506 Loss:  0.07789821177721024\n",
            "507 Loss:  0.07780659198760986\n",
            "508 Loss:  0.07771526277065277\n",
            "509 Loss:  0.07762417942285538\n",
            "510 Loss:  0.07753335684537888\n",
            "511 Loss:  0.07744277268648148\n",
            "512 Loss:  0.07735244184732437\n",
            "513 Loss:  0.07726239413022995\n",
            "514 Loss:  0.07717256993055344\n",
            "515 Loss:  0.07708299905061722\n",
            "516 Loss:  0.0769936814904213\n",
            "517 Loss:  0.07690460234880447\n",
            "518 Loss:  0.07681577652692795\n",
            "519 Loss:  0.07672719657421112\n",
            "520 Loss:  0.0766388475894928\n",
            "521 Loss:  0.07655075937509537\n",
            "522 Loss:  0.07646290957927704\n",
            "523 Loss:  0.07637527585029602\n",
            "524 Loss:  0.0762879028916359\n",
            "525 Loss:  0.07620076835155487\n",
            "526 Loss:  0.07611387223005295\n",
            "527 Loss:  0.07602721452713013\n",
            "528 Loss:  0.07594078779220581\n",
            "529 Loss:  0.0758545771241188\n",
            "530 Loss:  0.0757686197757721\n",
            "531 Loss:  0.0756828784942627\n",
            "532 Loss:  0.075597383081913\n",
            "533 Loss:  0.0755121186375618\n",
            "534 Loss:  0.07542707026004791\n",
            "535 Loss:  0.07534227520227432\n",
            "536 Loss:  0.07525768131017685\n",
            "537 Loss:  0.07517332583665848\n",
            "538 Loss:  0.07508918642997742\n",
            "539 Loss:  0.07500529289245605\n",
            "540 Loss:  0.07492160052061081\n",
            "541 Loss:  0.07483813911676407\n",
            "542 Loss:  0.07475488632917404\n",
            "543 Loss:  0.07467186450958252\n",
            "544 Loss:  0.07458905875682831\n",
            "545 Loss:  0.0745064839720726\n",
            "546 Loss:  0.07442411780357361\n",
            "547 Loss:  0.07434195280075073\n",
            "548 Loss:  0.07426002621650696\n",
            "549 Loss:  0.0741783082485199\n",
            "550 Loss:  0.07409679889678955\n",
            "551 Loss:  0.07401550561189651\n",
            "552 Loss:  0.07393442094326019\n",
            "553 Loss:  0.07385355234146118\n",
            "554 Loss:  0.07377289235591888\n",
            "555 Loss:  0.0736924409866333\n",
            "556 Loss:  0.07361220568418503\n",
            "557 Loss:  0.07353216409683228\n",
            "558 Loss:  0.07345234602689743\n",
            "559 Loss:  0.07337271422147751\n",
            "560 Loss:  0.0732933059334755\n",
            "561 Loss:  0.0732140839099884\n",
            "562 Loss:  0.07313507050275803\n",
            "563 Loss:  0.07305625826120377\n",
            "564 Loss:  0.07297767698764801\n",
            "565 Loss:  0.07289925962686539\n",
            "566 Loss:  0.07282105088233948\n",
            "567 Loss:  0.07274303585290909\n",
            "568 Loss:  0.07266523689031601\n",
            "569 Loss:  0.07258762419223785\n",
            "570 Loss:  0.07251021265983582\n",
            "571 Loss:  0.07243300974369049\n",
            "572 Loss:  0.07235598564147949\n",
            "573 Loss:  0.07227915525436401\n",
            "574 Loss:  0.07220252603292465\n",
            "575 Loss:  0.07212607562541962\n",
            "576 Loss:  0.07204984873533249\n",
            "577 Loss:  0.0719737708568573\n",
            "578 Loss:  0.07189790159463882\n",
            "579 Loss:  0.07182224094867706\n",
            "580 Loss:  0.07174674421548843\n",
            "581 Loss:  0.07167144864797592\n",
            "582 Loss:  0.07159634679555893\n",
            "583 Loss:  0.07152140140533447\n",
            "584 Loss:  0.07144667208194733\n",
            "585 Loss:  0.0713721290230751\n",
            "586 Loss:  0.07129774242639542\n",
            "587 Loss:  0.07122356444597244\n",
            "588 Loss:  0.0711495652794838\n",
            "589 Loss:  0.07107573002576828\n",
            "590 Loss:  0.07100209593772888\n",
            "591 Loss:  0.0709286481142044\n",
            "592 Loss:  0.07085537165403366\n",
            "593 Loss:  0.07078227400779724\n",
            "594 Loss:  0.07070934772491455\n",
            "595 Loss:  0.07063660770654678\n",
            "596 Loss:  0.07056404650211334\n",
            "597 Loss:  0.07049166411161423\n",
            "598 Loss:  0.07041944563388824\n",
            "599 Loss:  0.07034741342067719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "-nFLAosrKKlx",
        "outputId": "99c3613a-990f-4c4f-d2d7-e651cb847b95"
      },
      "source": [
        "plt.plot(losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f573882b3c8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ei9qWtVK0Ss"
      },
      "source": [
        "### 테스트 시작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY-j7E3wKXS7",
        "outputId": "606c4037-1c62-4b96-b837-d86553d04805"
      },
      "source": [
        "net.eval()\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "\r\n",
        "  test_result = net(x_test)\r\n",
        "  pred = torch.argmax(test_result, dim=1)\r\n",
        "\r\n",
        "  num_correct = (pred == y_test).sum().item()\r\n",
        "  print('Accuracy : ', num_correct*100.0 / len(y_test), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  95.55555555555556 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}